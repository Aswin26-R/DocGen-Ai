{"file_contents":{"app.py":{"content":"import streamlit as st\nimport os\nfrom backend.auth import check_authentication, render_login\nfrom backend.utils import initialize_session_state\n\n# Page configuration\nst.set_page_config(\n    page_title=\"DocGen - AI Documentation & Learning Assistant\",\n    page_icon=\"ðŸŽ“\",\n    layout=\"wide\",\n    initial_sidebar_state=\"expanded\"\n)\n\n# Initialize session state\ninitialize_session_state()\n\n# Authentication check\nif not check_authentication():\n    render_login()\n    st.stop()\n\n# Main application\nst.title(\"ðŸŽ“ DocGen - AI Documentation & Learning Assistant\")\nst.markdown(\"---\")\n\n# Welcome message\nst.markdown(\"\"\"\n### Welcome to DocGen! ðŸ‘‹\n\nTransform your documents and academic papers into interactive learning experiences with AI-powered:\n- **ðŸ“š Document Library**: Upload PDFs, DOCX, TXT files or search Arxiv papers\n- **ðŸ§  Quiz Center**: Generate multiple choice quizzes and sentence completion exercises\n- **ðŸ“ Summaries**: Create concise, markdown-formatted summaries\n- **ðŸ“Š Dashboard**: Track your learning progress and performance\n\n**Get Started:**\n1. Navigate to the Document Library to upload your first document\n2. Generate learning materials from your uploaded content\n3. Track your progress in the Dashboard\n\n---\n\"\"\")\n\n# Quick stats\ncol1, col2, col3, col4 = st.columns(4)\n\nwith col1:\n    st.metric(\n        label=\"ðŸ“„ Documents\",\n        value=len(st.session_state.get('documents', []))\n    )\n\nwith col2:\n    st.metric(\n        label=\"ðŸ“ Summaries\",\n        value=len(st.session_state.get('summaries', []))\n    )\n\nwith col3:\n    st.metric(\n        label=\"ðŸŽ¯ Quizzes Taken\",\n        value=len(st.session_state.get('quiz_history', []))\n    )\n\nwith col4:\n    avg_score = 0\n    if st.session_state.get('quiz_history'):\n        scores = [q.get('score', 0) for q in st.session_state.quiz_history]\n        avg_score = sum(scores) / len(scores)\n    st.metric(\n        label=\"ðŸ“ˆ Avg Score\",\n        value=f\"{avg_score:.1f}%\"\n    )\n\n# Recent activity\nst.subheader(\"ðŸ“… Recent Activity\")\nif st.session_state.get('activity_log'):\n    for activity in st.session_state.activity_log[-5:]:\n        st.info(f\"**{activity['timestamp']}** - {activity['action']}\")\nelse:\n    st.info(\"No recent activity. Start by uploading a document!\")\n\n# Quick actions\nst.subheader(\"ðŸš€ Quick Actions\")\ncol1, col2, col3 = st.columns(3)\n\nwith col1:\n    if st.button(\"ðŸ“¤ Upload Document\", use_container_width=True):\n        st.switch_page(\"pages/1_ðŸ“š_Document_Library.py\")\n\nwith col2:\n    if st.button(\"ðŸŽ¯ Take Quiz\", use_container_width=True):\n        st.switch_page(\"pages/2_ðŸ§ _Quiz_Center.py\")\n\nwith col3:\n    if st.button(\"ðŸ“Š View Dashboard\", use_container_width=True):\n        st.switch_page(\"pages/4_ðŸ“Š_Dashboard.py\")\n","size_bytes":2729},"pyproject.toml":{"content":"[project]\nname = \"repl-nix-workspace\"\nversion = \"0.1.0\"\ndescription = \"Add your description here\"\nrequires-python = \">=3.11\"\ndependencies = [\n    \"arxiv>=2.2.0\",\n    \"faiss-cpu>=1.12.0\",\n    \"google-genai>=1.41.0\",\n    \"pandas>=2.3.3\",\n    \"plotly>=6.3.1\",\n    \"pypdf2>=3.0.1\",\n    \"python-docx>=1.2.0\",\n    \"streamlit>=1.50.0\",\n]\n\n[[tool.uv.index]]\nexplicit = true\nname = \"pytorch-cpu\"\nurl = \"https://download.pytorch.org/whl/cpu\"\n\n[tool.uv.sources]\nAA-module = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nABlooper = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nAnalysisG = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nAutoRAG = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nBERTeam = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nBxTorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nByaldi = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nCALM-Pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nCOPEX-high-rate-compression-quality-metrics = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nCityLearn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nCoCa-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nCoLT5-attention = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nComfyUI-EasyNodes = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nCrawl4AI = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nDALL-E = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nDI-toolkit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nDatasetRising = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nDeepCache = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nDeepMatter = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nDraugr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nESRNN = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nEn-transformer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nExpoSeq = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nFLAML = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nFSRS-Optimizer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nGANDLF = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nGQLAlchemy = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nGhostScan = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nGraKeL = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nHEBO = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nIOPaint = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nISLP = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nInvokeAI = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nJAEN = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nKapoorLabs-Lightning = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nLightAutoML = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nLingerGRN = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nMMEdu = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nMRzeroCore = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nModeva = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nNeuralFoil = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nNiMARE = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nNinjaTools = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nOpenHosta = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nOpenNMT-py = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nPOT = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nPVNet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nPaLM-rlhf-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nPepperPepper = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nPiML = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nPoutyne = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nQNCP = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nRAGatouille = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nRareGO = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nRealtimeSTT = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nRelevanceAI-Workflows-Core = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nResemblyzer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nScandEval = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nSimba-UW-tf-dev = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nSwissArmyTransformer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nTPOT = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nTTS = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nTorchCRF = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nTotalSegmentator = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nUtilsRL = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nWhisperSpeech = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nXAISuite = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\na-unet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\na5dev = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naccelerate = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naccelerated-scan = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naccern-xyme = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nachatbot = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nacids-rave = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nactorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nacvl-utils = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nadabelief-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nadam-atan2-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nadan-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nadapters = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nadmin-torch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nadtoolbox = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nadversarial-robustness-toolbox = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naeiou = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naeon = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nafricanwhisper = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nag-llama-api = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nagentdojo = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nagilerl = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nai-edge-torch-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nai-parrot = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nai-python = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nai-transform = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nai2-olmo = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nai2-olmo-core = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nai2-tango = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naicmder = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naider-chat = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naider-chat-x = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naif360 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naihwkit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naimodelshare = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nairllm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nairtestProject = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nairunner = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naisak = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naislib = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naisquared = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naistore = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naithree = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nakasha-terminal = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nalibi = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nalibi-detect = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nalignn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nall-clip = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nallennlp = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nallennlp-models = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nallennlp-pvt-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nallophant = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nallosaurus = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naloy = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nalpaca-eval = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nalphafold2-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nalphafold3-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nalphamed-federated = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nalphawave = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\namazon-braket-pennylane-plugin = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\namazon-photos = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nanemoi-graphs = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nanemoi-models = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nanomalib = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\napache-beam = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\napache-tvm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naperturedb = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naphrodite-engine = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naqlm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\narcAGI2024 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\narchisound = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nargbind = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\narize = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\narm-pytorch-utilities = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\narray-api-compat = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\narus = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nassert-llm-tools = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nasteroid = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nasteroid-filterbanks = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nastra-llm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nastrovision = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\natomate2 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nattacut = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naudio-diffusion-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naudio-encoders-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naudio-separator = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naudiocraft = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naudiolm-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nauralis = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nauraloss = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nauto-gptq = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nautoawq = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nautoawq-kernels = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\n\"autogluon.multimodal\" = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\n\"autogluon.tabular\" = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\n\"autogluon.timeseries\" = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nautotrain-advanced = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\navdeepfake1m = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naws-fortuna = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nax-platform = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nazureml-automl-dnn-vision = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nazureml-contrib-automl-dnn-forecasting = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nazureml-evaluate-mlflow = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nazureml-metrics = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nazureml-train-automl = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nb2bTools = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbackpack-for-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbalrog-nle = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbatch-face = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbatchalign = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbatchgeneratorsv2 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbatchtensor = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbbrl = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbenchpots = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbent = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbert-score = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbertopic = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbertviz = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbestOf = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbetty-ml = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbig-sleep = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbigdl-core-cpp = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbigdl-core-npu = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbigdl-llm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbigdl-nano = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\n\"bioimageio.core\" = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbitfount = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbitsandbytes = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbittensor = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbittensor-cli = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nblackboxopt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nblanc = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nblindai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbm25-pt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nboltz = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbotorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nboxmot = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbrainchain = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbraindecode = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbrevitas = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbriton = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbrowsergym-visualwebarena = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbuzz-captions = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbyotrack = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbyzerllm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nc4v-py = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncalflops = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncame-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncamel-ai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncamel-tools = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncannai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncaptum = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncarte-ai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncarvekit-colab = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncatalyst = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncausalml = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncausalnex = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncausy = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncbrkit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncca-zoo = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncdp-backend = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncellacdc = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncellfinder = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncellpose = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncellxgene-census = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nchattts = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nchemprop = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nchgnet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nchitra = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncircuitsvis = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncjm-yolox-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclarinpl-embeddings = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclass-resolver = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclassifier-free-guidance-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclassiq = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclassy-core = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclean-fid = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncleanvision = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclip-anytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclip-benchmark = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclip-by-openai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclip-interrogator = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclip-retrieval = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncltk = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclu = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclusterops = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncnocr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncnstd = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncoba = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncofi = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncolbert-ai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncolpali-engine = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncompel = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncomposabl-ray = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncomposabl-ray-dev = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncomposabl-train = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncomposabl-train-dev = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncomposer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncompressai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncompressed-tensors = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncompressed-tensors-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nconcrete-python = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nconfit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nconformer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncontextualSpellCheck = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncontinual-inference = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncontrolnet-aux = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nconvokit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncoola = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncoqui-tts = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncoqui-tts-trainer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncraft-text-detector = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncreme = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncrocodile = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncrowd-kit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncryoSPHERE = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncsle-common = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncsle-system-identification = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nctgan = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncurated-transformers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncut-cross-entropy = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncvat-sdk = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncybertask = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nd3rlpy = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndalle-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndalle2-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndanila-lib = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndanling = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndarts = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndarwin-py = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndata-gradients = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndatachain = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndataclass-array = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndataeval = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndatarobot-drum = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndatarobotx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndatasets = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndatumaro = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndctorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeep-utils = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepchecks = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepchem = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepctr-torch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepecho = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepepochs = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepforest = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeeplabcut = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepmd-kit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepmultilingualpunctuation = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepparse = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeeprobust = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepsparse = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepsparse-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepspeed = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndenoising-diffusion-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndescript-audio-codec = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndescript-audiotools = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndetecto = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndetoxify = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndgenerate = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndghs-imgutils = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndgl = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndialogy = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndice-ml = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndiffgram = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndiffq = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndiffusers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndistilabel = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndistrifuser = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndnikit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndocarray = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndoclayout-yolo = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndocling-ibm-models = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndocquery = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndomino-code-assist = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndreamsim = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndropblock = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndruida = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndvclive = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ne2-tts-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ne2cnn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ne3nn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\neasyocr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nebtorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\necallisto-ng = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nedsnlp = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\neffdet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\neinx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\neir-dl = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\neis1600 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\neland = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nema-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nembedchain = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nenformer-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nentmax = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nesm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nespaloma-charge = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nespnet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\netils = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\netna = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nevadb = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nevalscope = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nevaluate = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nexllamav2 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nextractable = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nface-alignment = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfacenet-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfacexlib = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfair-esm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfairseq = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfairseq2 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfairseq2n = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfaker-file = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfarm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfast-bert = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfast-pytorch-kmeans = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfastai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfastcore = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfastestimator-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfasttreeshap = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfedml = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfelupe = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfemr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfft-conv-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfickling = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfireworks-ai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nflair = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nflashrag-dev = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nflax = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nflexgen = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nflgo = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nflopth = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nflowcept = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nflytekitplugins-kfpytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nflytekitplugins-onnxpytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfmbench = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfocal-frequency-loss = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfoldedtensor = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfractal-tasks-core = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfreegenius = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfreqtrade = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfschat = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfunasr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfunctorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfunlbm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfunsor = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngalore-torch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngarak = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngarf = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngateloop-transformer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngeffnet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngenutility = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngfpgan = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngigagan-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngin-config = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nglasflow = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngliner = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngluonts = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngmft = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngoogle-cloud-aiplatform = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngpforecaster = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngpt3discord = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngpytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngrad-cam = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngraph-weather = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngraphistry = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngravitorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngretel-synthetics = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngsplat = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nguardrails-ai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nguidance = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngymnasium = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhanlp = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhappytransformer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhbutils = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nheavyball = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhezar = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhf-deepali = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhf-doc-builder = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhigher = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhjxdl = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhkkang-utils = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhordelib = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhpsv2 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhuggingface-hub = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhummingbird-ml = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhvae-backbone = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhya = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhypothesis-torch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nibm-metrics-plugin = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nibm-watson-machine-learning = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nibm-watsonx-ai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nicetk = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nicevision = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\niden = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nidvpackage = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\niglovikov-helper-functions = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nimagededup = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nimagen-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nimaginAIry = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nimg2vec-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nincendio = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ninference = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ninference-gpu = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ninfinity-emb = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ninfo-nce-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ninfoapps-mlops-sdk = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ninstructlab = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ninstructlab-dolomite = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ninstructlab-eval = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ninstructlab-sdg = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ninstructlab-training = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ninvisible-watermark = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\niobm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nipex-llm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\niree-turbine = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nirisml = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nirisml-tasks-azure-openai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nirisml-tasks-torchvision = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nirisml-tasks-training = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nitem-matching = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nivadomed = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\njaqpotpy = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\njina = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\njudo = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\njunky = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nk-diffusion = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nk1lib = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nk2 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkappadata = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkappamodules = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkarbonn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkats = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkbnf = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkedro-datasets = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkeybert = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkeytotext = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkhoj = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkiui = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkonfuzio-sdk = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkornia = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkornia-moons = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkraken = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkwarray = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkwimage = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlabml-nn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlagent = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlaion-clap = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlale = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlama-cleaner = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlancedb = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlangcheck = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlangkit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlangroid = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlangtest = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlayoutparser = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nldp = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nleafmap = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nleap-ie = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nleibniz = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nleptonai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nletmedoit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlhotse = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlib310 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlibpecos = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlibrec-auto = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlibretranslate = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nliger-kernel = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nliger-kernel-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlightning = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlightning-bolts = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlightning-fabric = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlightning-habana = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlightning-lite = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlightrag = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlightweight-gan = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlightwood = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlinear-attention-transformer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlinear-operator = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlinformer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlinformer-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nliom-toolkit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlion-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlit-nlp = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlitdata = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlitelama = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlitgpt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllama-index-embeddings-adapter = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllama-index-embeddings-clip = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllama-index-embeddings-instructor = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllama-index-llms-huggingface = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllama-index-postprocessor-colbert-rerank = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllm-blender = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllm-foundry = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllm-guard = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllm-rs = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllm2vec = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllmcompressor = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllmlingua = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllmvm-cli = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlm-eval = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlmdeploy = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlmms-eval = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlocal-attention = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlovely-tensors = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlpips = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlycoris-lora = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmace-torch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmagic-pdf = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmagicsoup = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmagvit2-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmaite = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmanga-ocr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmanifest-ml = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmanipulation = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmarker-pdf = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmatgl = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmed-imagetools = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmedaka = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmedcat = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmedmnist = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmegablocks = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmegatron-energon = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmemos = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmeshgpt-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmetatensor-torch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmflux = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmia-vgg = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmiditok = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nminari = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nminicons = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nml2rt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmlagents = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmlbench-core = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmlcroissant = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmlpfile = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmlx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmlx-whisper = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmmaction2 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmmengine = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmmengine-lite = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmmocr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmmpose = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmmsegmentation = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmodeci-mdf = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmodel2vec = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmodelscope = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmodelspec = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmonai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmonai-weekly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmonotonic-alignment-search = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmonty = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmosaicml = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmosaicml-streaming = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmoshi = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmteb = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmtmtrain = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmulti-quantization = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmyhand = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnGPT-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnaeural-core = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnapari = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnapatrackmater = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnara-wpe = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnatten = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnbeats-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnebulae = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnemo-toolkit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nneptune = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nneptune-client = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnerfacc = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnerfstudio = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnessai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnetcal = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nneural-rag = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nneuralforecast = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nneuralnets = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nneuralprophet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nneuspell = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnevergrad = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnexfort = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnimblephysics = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnirtorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnkululeko = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnlp = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnlptooltest = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnnAudio = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnnodely = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnnsight = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnnunetv2 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnoisereduce = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnonebot-plugin-nailongremove = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnowcasting-dataloader = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnowcasting-forecast = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnshtrainer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnuwa-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnvflare = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnvidia-modelopt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nocf-datapipes = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nocnn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nogb = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nohmeow-blurr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nolive-ai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nomlt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nommlx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nonediff = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nonediffx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nonnx2pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nonnx2torch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopacus = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopen-clip-torch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopen-flamingo = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopen-interpreter = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopenbb-terminal-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopenmim = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopenparse = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopenunmix = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopenvino-dev = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopenvino-tokenizers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopenvino-xai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopenwakeword = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopt-einsum-fx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noptimum = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noptimum-habana = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noptimum-intel = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noptimum-neuron = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noptimum-quanto = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noptree = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noptuna = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noptuna-dashboard = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noptuna-integration = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noracle-ads = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\norbit-ml = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\notx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noutetts = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noutlines = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noutlines-core = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npaddlenlp = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npai-easycv = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npandasai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npanns-inference = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npatchwork-cli = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npeft = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npegasuspy = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npelutils = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npenn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nperforatedai-freemium = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nperformer-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npetastorm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npfio = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npgmpy = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nphenolrs = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nphobos = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npi-zero-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npinecone-text = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npiq = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npix2tex = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npix2text = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npnnx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npolicyengine-us-data = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npolyfuzz = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npomegranate = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npositional-encodings = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nprefigure = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nproduct-key-memory = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nptflops = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nptwt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npulser-core = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npunctuators = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npy2ls = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyabsa = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\n\"pyannote.audio\" = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyawd = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyclarity = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npycox = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyfemtet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyg-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npygrinder = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyhealth = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyhf = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyiqa = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npykeen = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npykeops = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npylance = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npylineaGT = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npymanopt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npymde = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npypots = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyqlib = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyqtorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyro-ppl = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npysentimiento = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyserini = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npysr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npythainlp = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npython-doctr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-fid = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-forecasting = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-ignite = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-kinematics = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-lightning = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-lightning-bolts = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-metric-learning = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-model-summary = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-msssim = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-pfn-extras = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-pretrained-bert = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-ranger = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-seed = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-tabnet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-tabular = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-toolbelt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-transformers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-transformers-pvt-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-triton-rocm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-warmup = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-wavelets = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch_optimizer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch_revgrad = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorchcv = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorchltr2 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyvene = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyvespa = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nqianfan = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nqibo = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nqiskit-machine-learning = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nqtorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nquanto = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nquick-anomaly-detector = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrastervision = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrastervision-pytorch-backend = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrastervision-pytorch-learner = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nray-lightning = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrclip = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrealesrgan = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrecbole = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrecommenders = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nredcat = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nreformer-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nregex-sampler = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nreplay-rec = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrerankers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nresearch-framework = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nresemble-enhance = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nresnest = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrf-clip = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrf-groundingdino = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrfconv = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrich-logger = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nring-attention-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrltrade-test = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrotary-embedding-torch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrsp-ml = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrust-circuit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ns2fft = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ns3prl = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ns3torchconnector = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsaferx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsafetensors = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsagemaker-huggingface-inference-toolkit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsagemaker-ssh-helper = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsalesforce-lavis = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsalesforce-merlion = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsamv2 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nscib = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nscib-metrics = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nscvi-tools = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsdmetrics = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsecretflow = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsegment-anything-hq = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsegment-anything-py = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsegmentation-models-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nself-rewarding-lm-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsemantic-kernel = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsemantic-router = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsenselab = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsent2vec = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsentence-transformers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsequence-model-train = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nserotiny = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsevenn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsglang = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nshap = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsilero-api-server = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsilero-vad = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsilicondiff-npu = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsimclr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsimple-lama-inpainting = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsinabs = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsixdrepnet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nskforecast = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nskorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nskrl = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nskt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsktime = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsktmls = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nslangtorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsmartnoise-synth = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsmashed = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsmplx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsmqtk-descriptors = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsmqtk-detection = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsnntorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsnorkel = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsnowflake-ml-python = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nso-vits-svc-fork = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsonusai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsony-custom-layers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsotopia = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspacr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspacy-curated-transformers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspacy-experimental = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspacy-huggingface-pipelines = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspacy-llm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspacy-transformers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspan-marker = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspandrel = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspandrel-extra-arches = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsparrow-python = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspatialdata = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspeechbrain = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspeechtokenizer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspikeinterface = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspikingjelly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspotiflow = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspotpython = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspotriver = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsquirrel-core = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nstable-baselines3 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nstable-diffusion-sdkit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nstable-ts = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nstanford-stk = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nstanfordnlp = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nstanza = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nstartorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nstreamtasks = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nstruct-eqtable = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nstylegan2-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsupar = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsuper-gradients = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsuper-image = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsuperlinked = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsupervisely = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsurya-ocr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsvdiff-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nswarm-models = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nswarmauri = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nswarms-memory = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nswebench = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsyft = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsympytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsyne-tune = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsynthcity = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nt5 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntab-transformer-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntabpfn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntaming-transformers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntaming-transformers-rom1504 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntaskwiz = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntbparse = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntecton = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntensor-parallel = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntensorcircuit-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntensordict = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntensordict-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntensorizer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntensorrt-llm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntexify = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntext2text = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntextattack = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntfkit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nthepipe-api = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nthinc = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nthingsvision = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nthirdai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nthop = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntianshou = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntidy3d = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntimesfm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntimm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntipo-kgen = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntmnt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntoad = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntomesd = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntop2vec = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-audiomentations = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-dct = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-delaunay = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-directml = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-ema = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-encoding = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-fidelity = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-geometric = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-geopooling = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-harmonics = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-kmeans = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-lr-finder = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-max-mem = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-npu = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-optimi = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-optimizer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-ort = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-pitch-shift = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-ppr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-pruning = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-snippets = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-stoi = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-struct = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-tensorrt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchani = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchattacks = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchaudio = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchbiggraph = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchcam = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchcde = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchcfm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchcrepe = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchdata = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchdatasets-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchdiffeq = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchdyn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchestra = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorcheval = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorcheval-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchextractor = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchfcpe = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchfun = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchfunc-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchgeo = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchgeometry = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchio = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchjpeg = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchlayers-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchmeta = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchmetrics = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchmocks = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchpack = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchpippy = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchpq = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchprofile = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchquantlib = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchrec = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchrec-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchrec-nightly-cpu = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchrl = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchrl-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchscale = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchsde = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchseg = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchserve = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchserve-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchsnapshot-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchsr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchstain = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchsummaryX = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchtext = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchtnt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchtnt-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchtyping = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchutil = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchvinecopulib = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchvision = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchviz = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchx-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchxrayvision = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntotalspineseg = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntracebloc-package-dev = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntrainer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntransformer-engine = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntransformer-lens = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntransformer-smaller-training-vocab = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntransformers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntransformers-domain-adaptation = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntransfusion-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntransparent-background = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntreescope = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntrolo = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntsai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntslearn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nttspod = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntxtai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntyro = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nu8darts = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nuhg = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nuitestrunner-syberos = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nultimate-rvc = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nultralytics = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nultralytics-thop = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nunav = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nunbabel-comet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nunderthesea = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nunfoldNd = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nunimernet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nunitorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nunitxt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nunsloth = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nunsloth-zoo = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nunstructured = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nunstructured-inference = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nutilsd = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nv-diffusion-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvIQA = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvectice = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvector-quantize-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvectorhub-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nversatile-audio-upscaler = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvertexai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvesin = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvgg-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvideo-representations-extractor = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nviser = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvision-datasets = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvisionmetrics = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvisu3d = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvit-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nviturka-nn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvllm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvllm-flash-attn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvocos = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvollseg = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvtorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nwavmark = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nwdoc = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nwhisper-live = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nwhisper-timestamped = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nwhisperx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nwilds = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nwordllama = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nworker-automate-hub = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nwxbtool = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nx-clip = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nx-transformers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nxaitk_saliency = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nxformers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nxgrammar = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nxinference = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nxtts-api-server = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nyolo-poser = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nyolov5 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nyolov7-package = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nyta-general-utils = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nzensvi = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nzetascale = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nzuko = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\n","size_bytes":90711},"backend/auth.py":{"content":"import streamlit as st\nimport hashlib\nimport os\nfrom typing import Optional\n\ndef hash_key(api_key: str) -> str:\n    \"\"\"Hash API key for secure storage\"\"\"\n    return hashlib.sha256(api_key.encode()).hexdigest()\n\ndef check_authentication() -> bool:\n    \"\"\"Check if user is authenticated with valid API key\"\"\"\n    return 'authenticated' in st.session_state and st.session_state.authenticated\n\ndef validate_gemini_key(api_key: str) -> bool:\n    \"\"\"Validate Gemini API key format (basic validation)\"\"\"\n    if not api_key:\n        return False\n    \n    # Basic format validation - Gemini keys typically start with certain patterns\n    if len(api_key) < 20:\n        return False\n    \n    # Additional validation could be added here\n    return True\n\ndef authenticate_user(api_key: str) -> bool:\n    \"\"\"Authenticate user with Gemini API key\"\"\"\n    if validate_gemini_key(api_key):\n        st.session_state.authenticated = True\n        st.session_state.gemini_api_key = api_key\n        st.session_state.user_id = hash_key(api_key)[:12]  # Use first 12 chars of hash as user ID\n        return True\n    return False\n\ndef logout():\n    \"\"\"Log out user and clear session\"\"\"\n    keys_to_remove = [\n        'authenticated', 'gemini_api_key', 'user_id', 'documents', \n        'summaries', 'quiz_history', 'activity_log'\n    ]\n    for key in keys_to_remove:\n        if key in st.session_state:\n            del st.session_state[key]\n\ndef render_login():\n    \"\"\"Render the login interface\"\"\"\n    st.title(\"ðŸ” Login to DocGen\")\n    st.markdown(\"---\")\n    \n    st.info(\"\"\"\n    **Welcome to DocGen!** \n    \n    To get started, please enter your Google Gemini API key. Your key is stored securely in your session and is not persisted.\n    \n    **Don't have an API key?** \n    1. Visit [Google AI Studio](https://makersuite.google.com/app/apikey)\n    2. Create a free account\n    3. Generate your API key\n    \"\"\")\n    \n    with st.form(\"login_form\"):\n        api_key = st.text_input(\n            \"Gemini API Key\", \n            type=\"password\",\n            placeholder=\"Enter your Gemini API key\",\n            help=\"Your API key will be stored securely in your session only\"\n        )\n        \n        col1, col2 = st.columns(2)\n        with col1:\n            submitted = st.form_submit_button(\"ðŸš€ Start Learning\", use_container_width=True)\n        \n        with col2:\n            if st.form_submit_button(\"â„¹ï¸ How to get API key\", use_container_width=True):\n                st.info(\"\"\"\n                **Steps to get your Gemini API key:**\n                1. Go to [Google AI Studio](https://makersuite.google.com/app/apikey)\n                2. Sign in with your Google account\n                3. Click \"Create API key\"\n                4. Copy the generated key and paste it above\n                \"\"\")\n    \n    if submitted:\n        if api_key:\n            with st.spinner(\"Validating API key...\"):\n                if authenticate_user(api_key):\n                    st.success(\"âœ… Authentication successful! Redirecting...\")\n                    st.rerun()\n                else:\n                    st.error(\"âŒ Invalid API key. Please check your key and try again.\")\n        else:\n            st.error(\"Please enter your Gemini API key.\")\n\ndef render_logout_button():\n    \"\"\"Render logout button in sidebar\"\"\"\n    with st.sidebar:\n        st.markdown(\"---\")\n        if st.button(\"ðŸšª Logout\", use_container_width=True):\n            logout()\n            st.rerun()\n        \n        # Display user info\n        if 'user_id' in st.session_state:\n            st.caption(f\"ðŸ‘¤ User: {st.session_state.user_id}\")\n","size_bytes":3593},"backend/embeddings.py":{"content":"import os\nimport pickle\nimport numpy as np\nfrom typing import List, Dict, Any, Optional\nimport streamlit as st\nfrom google import genai\nfrom google.genai import types\n\nclass DocumentEmbeddings:\n    \"\"\"FAISS-based vector storage for document embeddings using Gemini embeddings\"\"\"\n    \n    def __init__(self):\n        api_key = st.session_state.get('gemini_api_key') or os.environ.get(\"GEMINI_API_KEY\", \"\")\n        if api_key:\n            self.client = genai.Client(api_key=api_key)\n        else:\n            self.client = None\n        self.dimension = 768  # Gemini embedding dimension\n        self.documents = []\n        self.metadata = []\n        self.index_file = \"data/embeddings_index.pkl\"\n        self.load_index()\n    \n    def add_document(self, text: str, metadata: Dict[str, Any]):\n        \"\"\"Add a document to the vector store\"\"\"\n        try:\n            if not self.client:\n                st.warning(\"Embeddings not available. Search functionality will be limited.\")\n                return False\n                \n            # Split text into chunks\n            chunks = self._chunk_text(text, chunk_size=512, overlap=50)\n            \n            for i, chunk in enumerate(chunks):\n                # Store document and metadata\n                self.documents.append(chunk)\n                chunk_metadata = metadata.copy()\n                chunk_metadata['chunk_id'] = i\n                chunk_metadata['chunk_text'] = chunk\n                self.metadata.append(chunk_metadata)\n            \n            self.save_index()\n            return True\n        except Exception as e:\n            st.error(f\"Error adding document to embeddings: {e}\")\n            return False\n    \n    def search(self, query: str, k: int = 5) -> List[Dict[str, Any]]:\n        \"\"\"Search for similar documents using keyword matching\"\"\"\n        try:\n            if not self.documents:\n                return []\n            \n            # Simple keyword-based search as fallback\n            query_lower = query.lower()\n            query_words = set(query_lower.split())\n            \n            results = []\n            for i, (doc, meta) in enumerate(zip(self.documents, self.metadata)):\n                doc_lower = doc.lower()\n                doc_words = set(doc_lower.split())\n                \n                # Calculate simple similarity score based on word overlap\n                common_words = query_words.intersection(doc_words)\n                if common_words:\n                    score = len(common_words) / max(len(query_words), 1)\n                    result = meta.copy()\n                    result['similarity_score'] = float(score)\n                    result['text'] = doc\n                    results.append(result)\n            \n            # Sort by score and return top k\n            results.sort(key=lambda x: x['similarity_score'], reverse=True)\n            return results[:k]\n        except Exception as e:\n            st.error(f\"Error searching embeddings: {e}\")\n            return []\n    \n    def get_similar_chunks(self, document_id: str, k: int = 3) -> List[str]:\n        \"\"\"Get similar chunks from the same document\"\"\"\n        try:\n            # Find all chunks from the document\n            doc_chunks = []\n            for i, meta in enumerate(self.metadata):\n                if meta.get('document_id') == document_id:\n                    doc_chunks.append((i, self.documents[i]))\n            \n            if not doc_chunks:\n                return []\n            \n            # Return first k chunks or all if less than k\n            return [chunk[1] for chunk in doc_chunks[:k]]\n        except Exception as e:\n            st.error(f\"Error getting similar chunks: {e}\")\n            return []\n    \n    def remove_document(self, document_id: str):\n        \"\"\"Remove a document from the vector store\"\"\"\n        try:\n            # Find indices to remove\n            indices_to_remove = []\n            for i, meta in enumerate(self.metadata):\n                if meta.get('document_id') == document_id:\n                    indices_to_remove.append(i)\n            \n            # Remove from metadata and documents (reverse order to maintain indices)\n            for idx in reversed(indices_to_remove):\n                del self.metadata[idx]\n                del self.documents[idx]\n            \n            # Rebuild FAISS index\n            self._rebuild_index()\n            self.save_index()\n            return True\n        except Exception as e:\n            st.error(f\"Error removing document: {e}\")\n            return False\n    \n    def _chunk_text(self, text: str, chunk_size: int = 512, overlap: int = 50) -> List[str]:\n        \"\"\"Split text into overlapping chunks\"\"\"\n        words = text.split()\n        chunks = []\n        \n        for i in range(0, len(words), chunk_size - overlap):\n            chunk = ' '.join(words[i:i + chunk_size])\n            if chunk.strip():\n                chunks.append(chunk)\n        \n        return chunks if chunks else [text]\n    \n    def _rebuild_index(self):\n        \"\"\"Rebuild the index from current documents\"\"\"\n        pass\n    \n    def save_index(self):\n        \"\"\"Save index and metadata to disk\"\"\"\n        try:\n            os.makedirs(\"data\", exist_ok=True)\n            \n            with open(self.index_file, 'wb') as f:\n                pickle.dump({\n                    'documents': self.documents,\n                    'metadata': self.metadata\n                }, f)\n        except Exception as e:\n            st.error(f\"Error saving index: {e}\")\n    \n    def load_index(self):\n        \"\"\"Load index and metadata from disk\"\"\"\n        try:\n            if os.path.exists(self.index_file):\n                with open(self.index_file, 'rb') as f:\n                    data = pickle.load(f)\n                \n                self.documents = data.get('documents', [])\n                self.metadata = data.get('metadata', [])\n        except Exception as e:\n            # If loading fails, start with empty index\n            self.documents = []\n            self.metadata = []\n    \n    def get_document_stats(self) -> Dict[str, int]:\n        \"\"\"Get statistics about the document store\"\"\"\n        stats = {\n            'total_chunks': len(self.documents),\n            'total_documents': len(set(meta.get('document_id', '') for meta in self.metadata)),\n            'index_size': len(self.documents)\n        }\n        return stats\n","size_bytes":6364},"backend/orchestrator.py":{"content":"import json\nimport logging\nimport os\nfrom typing import List, Dict, Any\nfrom google import genai\nfrom google.genai import types\nimport streamlit as st\n\nclass AIOrchestrator:\n    \"\"\"LangChain-style orchestrator for AI-powered learning content generation\"\"\"\n    \n    def __init__(self):\n        api_key = st.session_state.get('gemini_api_key') or os.environ.get(\"GEMINI_API_KEY\", \"\")\n        if not api_key:\n            raise ValueError(\"Gemini API key not found in session or environment\")\n        self.client = genai.Client(api_key=api_key)\n        \n    def generate_summary(self, text: str, title: str = \"\") -> str:\n        \"\"\"Generate a comprehensive markdown-formatted summary\"\"\"\n        prompt = f\"\"\"\n        Please create a comprehensive markdown-formatted summary of the following document.\n        \n        Document Title: {title}\n        \n        Requirements:\n        - Use proper markdown formatting with headers, bullet points, and emphasis\n        - Include key concepts, main ideas, and important details\n        - Structure the summary logically with clear sections\n        - Keep it concise but comprehensive\n        - Use bullet points for lists and key points\n        \n        Document Content:\n        {text}\n        \"\"\"\n        \n        try:\n            response = self.client.models.generate_content(\n                model=\"gemini-2.5-flash\",\n                contents=prompt\n            )\n            return response.text or \"Failed to generate summary\"\n        except Exception as e:\n            logging.error(f\"Summary generation failed: {e}\")\n            return f\"Error generating summary: {str(e)}\"\n    \n    def generate_mcq_quiz(self, text: str, num_questions: int = 5) -> List[Dict[str, Any]]:\n        \"\"\"Generate multiple choice quiz questions from text\"\"\"\n        prompt = f\"\"\"\n        Generate {num_questions} multiple choice questions based on the following text.\n        \n        Requirements:\n        - Each question should test understanding of key concepts\n        - Provide 4 options (A, B, C, D) for each question\n        - Include the correct answer and explanation\n        - Questions should be challenging but fair\n        - Include page/section references where possible\n        \n        Return the response as a JSON array with this structure:\n        [\n            {{\n                \"question\": \"Question text here?\",\n                \"options\": {{\n                    \"A\": \"Option A text\",\n                    \"B\": \"Option B text\", \n                    \"C\": \"Option C text\",\n                    \"D\": \"Option D text\"\n                }},\n                \"correct_answer\": \"A\",\n                \"explanation\": \"Detailed explanation of why A is correct\",\n                \"reference\": \"Section or page reference if available\"\n            }}\n        ]\n        \n        Text content:\n        {text}\n        \"\"\"\n        \n        try:\n            response = self.client.models.generate_content(\n                model=\"gemini-2.5-pro\",\n                contents=prompt,\n                config=types.GenerateContentConfig(\n                    response_mime_type=\"application/json\"\n                )\n            )\n            \n            if response.text:\n                questions = json.loads(response.text)\n                return questions\n            else:\n                return []\n        except Exception as e:\n            logging.error(f\"MCQ generation failed: {e}\")\n            return [{\"error\": f\"Failed to generate quiz: {str(e)}\"}]\n    \n    def generate_completion_exercise(self, text: str, num_questions: int = 5) -> List[Dict[str, Any]]:\n        \"\"\"Generate sentence completion exercises\"\"\"\n        prompt = f\"\"\"\n        Generate {num_questions} sentence completion exercises based on the following text.\n        \n        Requirements:\n        - Create sentences with key terms or concepts removed\n        - The missing part should be a single word or short phrase\n        - Include the correct answer and explanation\n        - Focus on important concepts and terminology\n        \n        Return as JSON array:\n        [\n            {{\n                \"sentence\": \"The process of _____ is essential for...\",\n                \"correct_answer\": \"photosynthesis\",\n                \"explanation\": \"Explanation of the concept\",\n                \"hint\": \"Optional hint for the user\"\n            }}\n        ]\n        \n        Text content:\n        {text}\n        \"\"\"\n        \n        try:\n            response = self.client.models.generate_content(\n                model=\"gemini-2.5-pro\",\n                contents=prompt,\n                config=types.GenerateContentConfig(\n                    response_mime_type=\"application/json\"\n                )\n            )\n            \n            if response.text:\n                exercises = json.loads(response.text)\n                return exercises\n            else:\n                return []\n        except Exception as e:\n            logging.error(f\"Completion exercise generation failed: {e}\")\n            return [{\"error\": f\"Failed to generate exercises: {str(e)}\"}]\n    \n    def evaluate_answer(self, question: str, correct_answer: str, user_answer: str) -> Dict[str, Any]:\n        \"\"\"Evaluate user answer using semantic similarity\"\"\"\n        prompt = f\"\"\"\n        Evaluate the similarity between the correct answer and the user's answer.\n        \n        Question: {question}\n        Correct Answer: {correct_answer}\n        User Answer: {user_answer}\n        \n        Provide:\n        1. A similarity score from 0-100\n        2. Feedback explaining the evaluation\n        3. Whether the answer should be considered correct (threshold: 70%)\n        \n        Return as JSON:\n        {{\n            \"score\": 85,\n            \"is_correct\": true,\n            \"feedback\": \"Detailed feedback explaining the evaluation\"\n        }}\n        \"\"\"\n        \n        try:\n            response = self.client.models.generate_content(\n                model=\"gemini-2.5-pro\",\n                contents=prompt,\n                config=types.GenerateContentConfig(\n                    response_mime_type=\"application/json\"\n                )\n            )\n            \n            if response.text:\n                evaluation = json.loads(response.text)\n                return evaluation\n            else:\n                return {\"score\": 0, \"is_correct\": False, \"feedback\": \"Evaluation failed\"}\n        except Exception as e:\n            logging.error(f\"Answer evaluation failed: {e}\")\n            return {\"score\": 0, \"is_correct\": False, \"feedback\": f\"Error: {str(e)}\"}\n    \n    def extract_key_concepts(self, text: str) -> List[str]:\n        \"\"\"Extract key concepts and terms from text\"\"\"\n        prompt = f\"\"\"\n        Extract the main concepts, key terms, and important ideas from the following text.\n        Return as a JSON array of strings, with each concept being a word or short phrase.\n        Focus on the most important 10-15 concepts.\n        \n        Text:\n        {text}\n        \"\"\"\n        \n        try:\n            response = self.client.models.generate_content(\n                model=\"gemini-2.5-flash\",\n                contents=prompt,\n                config=types.GenerateContentConfig(\n                    response_mime_type=\"application/json\"\n                )\n            )\n            \n            if response.text:\n                concepts = json.loads(response.text)\n                return concepts if isinstance(concepts, list) else []\n            else:\n                return []\n        except Exception as e:\n            logging.error(f\"Concept extraction failed: {e}\")\n            return []\n","size_bytes":7582},"backend/utils.py":{"content":"import streamlit as st\nimport PyPDF2\nimport docx\nimport io\nimport arxiv\nfrom typing import Optional, Dict, Any, List\nfrom datetime import datetime\nimport uuid\n\ndef initialize_session_state():\n    \"\"\"Initialize session state variables\"\"\"\n    if 'documents' not in st.session_state:\n        st.session_state.documents = []\n    \n    if 'summaries' not in st.session_state:\n        st.session_state.summaries = []\n    \n    if 'quiz_history' not in st.session_state:\n        st.session_state.quiz_history = []\n    \n    if 'activity_log' not in st.session_state:\n        st.session_state.activity_log = []\n    \n    if 'current_quiz' not in st.session_state:\n        st.session_state.current_quiz = None\n    \n    if 'quiz_state' not in st.session_state:\n        st.session_state.quiz_state = {}\n\ndef log_activity(action: str):\n    \"\"\"Log user activity with timestamp\"\"\"\n    activity = {\n        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M'),\n        'action': action,\n        'user_id': st.session_state.get('user_id', 'anonymous')\n    }\n    st.session_state.activity_log.append(activity)\n    \n    # Keep only last 50 activities\n    if len(st.session_state.activity_log) > 50:\n        st.session_state.activity_log = st.session_state.activity_log[-50:]\n\ndef extract_text_from_pdf(file_bytes: bytes) -> str:\n    \"\"\"Extract text from PDF file\"\"\"\n    try:\n        pdf_file = io.BytesIO(file_bytes)\n        pdf_reader = PyPDF2.PdfReader(pdf_file)\n        \n        text = \"\"\n        for page in pdf_reader.pages:\n            text += page.extract_text() + \"\\n\"\n        \n        return text.strip()\n    except Exception as e:\n        st.error(f\"Error extracting text from PDF: {e}\")\n        return \"\"\n\ndef extract_text_from_docx(file_bytes: bytes) -> str:\n    \"\"\"Extract text from DOCX file\"\"\"\n    try:\n        doc = docx.Document(io.BytesIO(file_bytes))\n        text = \"\"\n        \n        for paragraph in doc.paragraphs:\n            text += paragraph.text + \"\\n\"\n        \n        return text.strip()\n    except Exception as e:\n        st.error(f\"Error extracting text from DOCX: {e}\")\n        return \"\"\n\ndef extract_text_from_txt(file_bytes: bytes) -> str:\n    \"\"\"Extract text from TXT file\"\"\"\n    try:\n        return file_bytes.decode('utf-8')\n    except UnicodeDecodeError:\n        try:\n            return file_bytes.decode('latin1')\n        except Exception as e:\n            st.error(f\"Error reading text file: {e}\")\n            return \"\"\n\ndef process_uploaded_file(uploaded_file) -> Optional[Dict[str, Any]]:\n    \"\"\"Process uploaded file and extract text\"\"\"\n    if not uploaded_file:\n        return None\n    \n    file_bytes = uploaded_file.read()\n    file_type = uploaded_file.type\n    file_name = uploaded_file.name\n    \n    # Extract text based on file type\n    text = \"\"\n    if file_type == \"application/pdf\" or file_name.lower().endswith('.pdf'):\n        text = extract_text_from_pdf(file_bytes)\n    elif file_type == \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\" or file_name.lower().endswith('.docx'):\n        text = extract_text_from_docx(file_bytes)\n    elif file_type == \"text/plain\" or file_name.lower().endswith('.txt'):\n        text = extract_text_from_txt(file_bytes)\n    else:\n        st.error(f\"Unsupported file type: {file_type}\")\n        return None\n    \n    if not text.strip():\n        st.error(\"No text could be extracted from the file.\")\n        return None\n    \n    # Create document record\n    document = {\n        'id': str(uuid.uuid4()),\n        'title': file_name,\n        'content': text,\n        'type': 'uploaded',\n        'file_type': file_type,\n        'uploaded_at': datetime.now().isoformat(),\n        'word_count': len(text.split()),\n        'source': 'upload'\n    }\n    \n    return document\n\ndef search_arxiv_papers(query: str, max_results: int = 10) -> List[Dict[str, Any]]:\n    \"\"\"Search for papers on Arxiv\"\"\"\n    try:\n        client = arxiv.Client()\n        search = arxiv.Search(\n            query=query,\n            max_results=max_results,\n            sort_by=arxiv.SortCriterion.Relevance\n        )\n        \n        papers = []\n        for result in client.results(search):\n            paper = {\n                'title': result.title,\n                'authors': [author.name for author in result.authors],\n                'abstract': result.summary,\n                'url': result.entry_id,\n                'pdf_url': result.pdf_url,\n                'published': result.published.strftime('%Y-%m-%d'),\n                'categories': result.categories\n            }\n            papers.append(paper)\n        \n        return papers\n    except Exception as e:\n        st.error(f\"Error searching Arxiv: {e}\")\n        return []\n\ndef download_arxiv_paper(paper_url: str) -> Optional[Dict[str, Any]]:\n    \"\"\"Download and process Arxiv paper\"\"\"\n    try:\n        client = arxiv.Client()\n        paper = next(client.results(arxiv.Search(id_list=[paper_url.split('/')[-1]])))\n        \n        # Download PDF\n        pdf_path = paper.download_pdf(dirpath=\"./data/temp/\")\n        \n        # Extract text from PDF\n        with open(pdf_path, 'rb') as file:\n            text = extract_text_from_pdf(file.read())\n        \n        # Clean up temp file\n        import os\n        os.remove(pdf_path)\n        \n        if not text.strip():\n            return None\n        \n        # Create document record\n        document = {\n            'id': str(uuid.uuid4()),\n            'title': paper.title,\n            'content': text,\n            'type': 'arxiv',\n            'authors': [author.name for author in paper.authors],\n            'abstract': paper.summary,\n            'url': paper.entry_id,\n            'published': paper.published.strftime('%Y-%m-%d'),\n            'downloaded_at': datetime.now().isoformat(),\n            'word_count': len(text.split()),\n            'source': 'arxiv'\n        }\n        \n        return document\n    except Exception as e:\n        st.error(f\"Error downloading Arxiv paper: {e}\")\n        return None\n\ndef calculate_reading_time(word_count: int, wpm: int = 200) -> str:\n    \"\"\"Calculate estimated reading time\"\"\"\n    minutes = word_count / wpm\n    if minutes < 1:\n        return \"< 1 min\"\n    elif minutes < 60:\n        return f\"{int(minutes)} min\"\n    else:\n        hours = int(minutes // 60)\n        mins = int(minutes % 60)\n        return f\"{hours}h {mins}m\"\n\ndef format_file_size(size_bytes: int) -> str:\n    \"\"\"Format file size in human readable format\"\"\"\n    if size_bytes < 1024:\n        return f\"{size_bytes} B\"\n    elif size_bytes < 1024 * 1024:\n        return f\"{size_bytes / 1024:.1f} KB\"\n    else:\n        return f\"{size_bytes / (1024 * 1024):.1f} MB\"\n\ndef get_document_by_id(doc_id: str) -> Optional[Dict[str, Any]]:\n    \"\"\"Get document by ID\"\"\"\n    for doc in st.session_state.documents:\n        if doc['id'] == doc_id:\n            return doc\n    return None\n\ndef remove_document_by_id(doc_id: str) -> bool:\n    \"\"\"Remove document by ID\"\"\"\n    for i, doc in enumerate(st.session_state.documents):\n        if doc['id'] == doc_id:\n            del st.session_state.documents[i]\n            log_activity(f\"Deleted document: {doc['title']}\")\n            return True\n    return False\n","size_bytes":7177},"pages/1_ðŸ“š_Document_Library.py":{"content":"import streamlit as st\nimport os\nfrom backend.auth import check_authentication, render_logout_button\nfrom backend.utils import (\n    initialize_session_state, process_uploaded_file, search_arxiv_papers,\n    download_arxiv_paper, log_activity, get_document_by_id, remove_document_by_id,\n    calculate_reading_time\n)\nfrom backend.embeddings import DocumentEmbeddings\n\n# Page configuration\nst.set_page_config(\n    page_title=\"Document Library - DocGen\",\n    page_icon=\"ðŸ“š\",\n    layout=\"wide\"\n)\n\n# Authentication check\nif not check_authentication():\n    st.error(\"Please log in from the main page first.\")\n    st.stop()\n\n# Initialize session state\ninitialize_session_state()\n\n# Render logout button\nrender_logout_button()\n\n# Initialize embeddings\n@st.cache_resource\ndef get_embeddings():\n    return DocumentEmbeddings()\n\nembeddings = get_embeddings()\n\nst.title(\"ðŸ“š Document Library\")\nst.markdown(\"Upload documents or search Arxiv papers to build your learning library.\")\n\n# Tabs for different actions\ntab1, tab2, tab3 = st.tabs([\"ðŸ“¤ Upload Documents\", \"ðŸ” Search Arxiv\", \"ðŸ“‹ My Documents\"])\n\nwith tab1:\n    st.subheader(\"Upload Your Documents\")\n    st.markdown(\"Support formats: PDF, DOCX, TXT\")\n    \n    uploaded_files = st.file_uploader(\n        \"Choose files\",\n        accept_multiple_files=True,\n        type=['pdf', 'docx', 'txt'],\n        help=\"Upload PDF, DOCX, or TXT files to add to your library\"\n    )\n    \n    if uploaded_files:\n        if st.button(\"ðŸ“¥ Process Uploaded Files\", type=\"primary\"):\n            progress_bar = st.progress(0)\n            status_text = st.empty()\n            \n            processed_count = 0\n            \n            for i, uploaded_file in enumerate(uploaded_files):\n                status_text.text(f\"Processing: {uploaded_file.name}\")\n                \n                # Process file\n                document = process_uploaded_file(uploaded_file)\n                \n                if document:\n                    # Add to session state\n                    st.session_state.documents.append(document)\n                    \n                    # Add to vector store\n                    embeddings.add_document(\n                        document['content'],\n                        {\n                            'document_id': document['id'],\n                            'title': document['title'],\n                            'type': document['type'],\n                            'source': document['source']\n                        }\n                    )\n                    \n                    processed_count += 1\n                    log_activity(f\"Uploaded document: {document['title']}\")\n                \n                progress_bar.progress((i + 1) / len(uploaded_files))\n            \n            status_text.text(f\"âœ… Processed {processed_count} documents successfully!\")\n            \n            if processed_count > 0:\n                st.success(f\"Added {processed_count} documents to your library!\")\n                st.rerun()\n\nwith tab2:\n    st.subheader(\"Search Academic Papers\")\n    st.markdown(\"Search and import papers from Arxiv\")\n    \n    col1, col2 = st.columns([3, 1])\n    with col1:\n        arxiv_query = st.text_input(\n            \"Search query\",\n            placeholder=\"e.g., machine learning, neural networks, quantum computing\",\n            help=\"Enter keywords to search for papers on Arxiv\"\n        )\n    with col2:\n        max_results = st.selectbox(\"Max results\", [5, 10, 15, 20], index=1)\n    \n    if arxiv_query and st.button(\"ðŸ” Search Arxiv\", type=\"primary\"):\n        with st.spinner(\"Searching Arxiv...\"):\n            papers = search_arxiv_papers(arxiv_query, max_results)\n        \n        if papers:\n            st.success(f\"Found {len(papers)} papers\")\n            \n            for i, paper in enumerate(papers):\n                with st.expander(f\"ðŸ“„ {paper['title'][:100]}...\"):\n                    st.markdown(f\"**Authors:** {', '.join(paper['authors'])}\")\n                    st.markdown(f\"**Published:** {paper['published']}\")\n                    st.markdown(f\"**Categories:** {', '.join(paper['categories'])}\")\n                    st.markdown(f\"**Abstract:** {paper['abstract'][:300]}...\")\n                    \n                    col1, col2 = st.columns(2)\n                    with col1:\n                        if st.button(f\"ðŸ“¥ Download Paper\", key=f\"download_{i}\"):\n                            with st.spinner(\"Downloading and processing...\"):\n                                document = download_arxiv_paper(paper['url'])\n                            \n                            if document:\n                                # Add to session state\n                                st.session_state.documents.append(document)\n                                \n                                # Add to vector store\n                                embeddings.add_document(\n                                    document['content'],\n                                    {\n                                        'document_id': document['id'],\n                                        'title': document['title'],\n                                        'type': document['type'],\n                                        'source': document['source']\n                                    }\n                                )\n                                \n                                log_activity(f\"Downloaded paper: {document['title']}\")\n                                st.success(\"Paper added to your library!\")\n                                st.rerun()\n                            else:\n                                st.error(\"Failed to download paper\")\n                    \n                    with col2:\n                        st.link_button(\"ðŸ”— View on Arxiv\", paper['url'])\n        else:\n            st.info(\"No papers found. Try different keywords.\")\n\nwith tab3:\n    st.subheader(\"My Document Library\")\n    \n    if not st.session_state.documents:\n        st.info(\"No documents in your library yet. Upload some documents or search Arxiv papers!\")\n    else:\n        # Library stats\n        col1, col2, col3 = st.columns(3)\n        with col1:\n            st.metric(\"ðŸ“„ Total Documents\", len(st.session_state.documents))\n        with col2:\n            total_words = sum(doc.get('word_count', 0) for doc in st.session_state.documents)\n            st.metric(\"ðŸ“ Total Words\", f\"{total_words:,}\")\n        with col3:\n            reading_time = calculate_reading_time(total_words)\n            st.metric(\"â±ï¸ Reading Time\", reading_time)\n        \n        st.markdown(\"---\")\n        \n        # Search within library\n        search_query = st.text_input(\n            \"ðŸ” Search your documents\",\n            placeholder=\"Search by title or content...\",\n            help=\"Search through your document library\"\n        )\n        \n        if search_query:\n            with st.spinner(\"Searching...\"):\n                results = embeddings.search(search_query, k=10)\n            \n            if results:\n                st.success(f\"Found {len(results)} relevant documents\")\n                for result in results:\n                    doc = get_document_by_id(result['document_id'])\n                    if doc:\n                        with st.expander(f\"ðŸ“„ {doc['title']} (Score: {result['similarity_score']:.2f})\"):\n                            st.markdown(f\"**Type:** {doc['type'].title()}\")\n                            st.markdown(f\"**Words:** {doc.get('word_count', 0):,}\")\n                            st.markdown(f\"**Content Preview:** {result['text'][:200]}...\")\n            else:\n                st.info(\"No documents found matching your search.\")\n        \n        # Document list\n        st.subheader(\"All Documents\")\n        \n        for doc in st.session_state.documents:\n            with st.expander(f\"ðŸ“„ {doc['title']}\"):\n                col1, col2 = st.columns([3, 1])\n                \n                with col1:\n                    st.markdown(f\"**Type:** {doc['type'].title()}\")\n                    st.markdown(f\"**Words:** {doc.get('word_count', 0):,}\")\n                    st.markdown(f\"**Added:** {doc.get('uploaded_at', doc.get('downloaded_at', 'Unknown'))[:10]}\")\n                    \n                    if doc.get('authors'):\n                        st.markdown(f\"**Authors:** {', '.join(doc['authors'])}\")\n                    \n                    # Content preview\n                    preview = doc['content'][:300]\n                    st.markdown(f\"**Preview:** {preview}...\")\n                \n                with col2:\n                    # Action buttons\n                    if st.button(f\"ðŸ“ Summarize\", key=f\"sum_{doc['id']}\"):\n                        st.session_state.selected_doc_for_summary = doc['id']\n                        st.switch_page(\"pages/3_ðŸ“_Summaries.py\")\n                    \n                    if st.button(f\"ðŸ§  Create Quiz\", key=f\"quiz_{doc['id']}\"):\n                        st.session_state.selected_doc_for_quiz = doc['id']\n                        st.switch_page(\"pages/2_ðŸ§ _Quiz_Center.py\")\n                    \n                    if st.button(f\"ðŸ—‘ï¸ Delete\", key=f\"del_{doc['id']}\", type=\"secondary\"):\n                        if remove_document_by_id(doc['id']):\n                            embeddings.remove_document(doc['id'])\n                            st.success(\"Document deleted!\")\n                            st.rerun()\n\n# Vector store statistics\nwith st.sidebar:\n    st.subheader(\"ðŸ“Š Library Stats\")\n    stats = embeddings.get_document_stats()\n    st.metric(\"Vector Chunks\", stats['total_chunks'])\n    st.metric(\"Indexed Documents\", stats['total_documents'])\n    st.metric(\"Search Index Size\", stats['index_size'])\n","size_bytes":9688},"pages/2_ðŸ§ _Quiz_Center.py":{"content":"import streamlit as st\nfrom backend.auth import check_authentication, render_logout_button\nfrom backend.utils import initialize_session_state, log_activity, get_document_by_id\nfrom backend.orchestrator import AIOrchestrator\nfrom datetime import datetime\nimport json\n\n# Page configuration\nst.set_page_config(\n    page_title=\"Quiz Center - DocGen\",\n    page_icon=\"ðŸ§ \",\n    layout=\"wide\"\n)\n\n# Authentication check\nif not check_authentication():\n    st.error(\"Please log in from the main page first.\")\n    st.stop()\n\n# Initialize session state\ninitialize_session_state()\n\n# Render logout button\nrender_logout_button()\n\n# Initialize AI orchestrator\n@st.cache_resource\ndef get_orchestrator():\n    return AIOrchestrator()\n\ntry:\n    orchestrator = get_orchestrator()\nexcept ValueError as e:\n    st.error(f\"AI Service Error: {e}\")\n    st.stop()\n\nst.title(\"ðŸ§  Quiz Center\")\nst.markdown(\"Generate and take AI-powered quizzes from your documents.\")\n\n# Check if a document was selected for quiz\nselected_doc_id = st.session_state.get('selected_doc_for_quiz')\n\nif not st.session_state.documents:\n    st.warning(\"No documents in your library. Please upload documents first.\")\n    if st.button(\"ðŸ“š Go to Document Library\"):\n        st.switch_page(\"pages/1_ðŸ“š_Document_Library.py\")\n    st.stop()\n\n# Tabs for different quiz modes\ntab1, tab2, tab3, tab4 = st.tabs([\"ðŸŽ¯ Multiple Choice\", \"âœï¸ Sentence Completion\", \"ðŸ’¬ Q&A Exercise\", \"ðŸ“ˆ Quiz History\"])\n\nwith tab1:\n    st.subheader(\"Multiple Choice Quiz\")\n    \n    # Document selection\n    doc_options = {doc['title']: doc['id'] for doc in st.session_state.documents}\n    selected_title = st.selectbox(\n        \"Select Document\",\n        options=list(doc_options.keys()),\n        index=list(doc_options.values()).index(selected_doc_id) if selected_doc_id in doc_options.values() else 0\n    )\n    selected_doc = get_document_by_id(doc_options[selected_title])\n    \n    # Quiz settings\n    col1, col2 = st.columns(2)\n    with col1:\n        num_questions = st.slider(\"Number of questions\", 3, 10, 5)\n    with col2:\n        difficulty = st.select_slider(\"Difficulty\", [\"Easy\", \"Medium\", \"Hard\"], \"Medium\")\n    \n    # Generate quiz\n    if st.button(\"ðŸŽ² Generate Quiz\", type=\"primary\"):\n        with st.spinner(\"Generating quiz questions...\"):\n            quiz_data = orchestrator.generate_mcq_quiz(\n                selected_doc['content'],\n                num_questions=num_questions\n            )\n        \n        if quiz_data and 'error' not in quiz_data[0]:\n            st.session_state.current_quiz = {\n                'type': 'multiple_choice',\n                'document_id': selected_doc['id'],\n                'document_title': selected_doc['title'],\n                'questions': quiz_data,\n                'answers': {},\n                'started_at': datetime.now().isoformat(),\n                'difficulty': difficulty\n            }\n            st.success(\"Quiz generated! Answer the questions below.\")\n        else:\n            st.error(\"Failed to generate quiz. Please try again.\")\n    \n    # Display current quiz\n    if st.session_state.current_quiz and st.session_state.current_quiz['type'] == 'multiple_choice':\n        quiz = st.session_state.current_quiz\n        st.markdown(\"---\")\n        st.subheader(f\"Quiz: {quiz['document_title']}\")\n        \n        all_answered = True\n        \n        for i, question in enumerate(quiz['questions']):\n            st.markdown(f\"**Question {i+1}:** {question['question']}\")\n            \n            answer = st.radio(\n                \"Choose your answer:\",\n                options=list(question['options'].keys()),\n                format_func=lambda x: f\"{x}: {question['options'][x]}\",\n                key=f\"mcq_{i}\",\n                index=None\n            )\n            \n            if answer:\n                quiz['answers'][i] = answer\n            else:\n                all_answered = False\n            \n            st.markdown(\"---\")\n        \n        # Submit quiz\n        if all_answered:\n            if st.button(\"âœ… Submit Quiz\", type=\"primary\"):\n                # Calculate score\n                correct_count = 0\n                total_questions = len(quiz['questions'])\n                \n                for i, question in enumerate(quiz['questions']):\n                    if quiz['answers'].get(i) == question['correct_answer']:\n                        correct_count += 1\n                \n                score = (correct_count / total_questions) * 100\n                \n                # Show results\n                st.success(f\"Quiz completed! Score: {score:.1f}% ({correct_count}/{total_questions})\")\n                \n                # Show detailed feedback\n                st.subheader(\"ðŸ“‹ Detailed Results\")\n                for i, question in enumerate(quiz['questions']):\n                    user_answer = quiz['answers'].get(i)\n                    is_correct = user_answer == question['correct_answer']\n                    \n                    status_icon = \"âœ…\" if is_correct else \"âŒ\"\n                    st.markdown(f\"{status_icon} **Question {i+1}:** {question['question']}\")\n                    \n                    if not is_correct:\n                        st.markdown(f\"Your answer: **{user_answer}** - {question['options'][user_answer]}\")\n                        st.markdown(f\"Correct answer: **{question['correct_answer']}** - {question['options'][question['correct_answer']]}\")\n                    \n                    st.markdown(f\"*Explanation:* {question['explanation']}\")\n                    \n                    if question.get('reference'):\n                        st.markdown(f\"*Reference:* {question['reference']}\")\n                    \n                    st.markdown(\"---\")\n                \n                # Save to history\n                quiz_result = {\n                    'id': f\"quiz_{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n                    'type': 'multiple_choice',\n                    'document_id': quiz['document_id'],\n                    'document_title': quiz['document_title'],\n                    'score': score,\n                    'total_questions': total_questions,\n                    'correct_answers': correct_count,\n                    'completed_at': datetime.now().isoformat(),\n                    'difficulty': quiz.get('difficulty', 'Medium'),\n                    'time_taken': 'Not tracked'  # Could implement timer\n                }\n                st.session_state.quiz_history.append(quiz_result)\n                log_activity(f\"Completed MCQ quiz on {quiz['document_title']} - Score: {score:.1f}%\")\n                \n                # Clear current quiz\n                st.session_state.current_quiz = None\n                \n                st.balloons()\n\nwith tab2:\n    st.subheader(\"Sentence Completion Exercise\")\n    \n    # Document selection\n    doc_options = {doc['title']: doc['id'] for doc in st.session_state.documents}\n    selected_title = st.selectbox(\n        \"Select Document\",\n        options=list(doc_options.keys()),\n        key=\"completion_doc\"\n    )\n    selected_doc = get_document_by_id(doc_options[selected_title])\n    \n    # Settings\n    num_exercises = st.slider(\"Number of exercises\", 3, 10, 5, key=\"completion_num\")\n    \n    # Generate exercises\n    if st.button(\"ðŸŽ¯ Generate Exercises\", type=\"primary\"):\n        with st.spinner(\"Generating completion exercises...\"):\n            exercises = orchestrator.generate_completion_exercise(\n                selected_doc['content'],\n                num_questions=num_exercises\n            )\n        \n        if exercises and 'error' not in exercises[0]:\n            st.session_state.current_completion = {\n                'document_id': selected_doc['id'],\n                'document_title': selected_doc['title'],\n                'exercises': exercises,\n                'answers': {},\n                'started_at': datetime.now().isoformat()\n            }\n            st.success(\"Exercises generated!\")\n        else:\n            st.error(\"Failed to generate exercises. Please try again.\")\n    \n    # Display exercises\n    if st.session_state.get('current_completion'):\n        completion = st.session_state.current_completion\n        st.markdown(\"---\")\n        st.subheader(f\"Completion Exercise: {completion['document_title']}\")\n        \n        for i, exercise in enumerate(completion['exercises']):\n            st.markdown(f\"**Exercise {i+1}:**\")\n            st.markdown(f\"{exercise['sentence']}\")\n            \n            if exercise.get('hint'):\n                with st.expander(\"ðŸ’¡ Hint\"):\n                    st.info(exercise['hint'])\n            \n            answer = st.text_input(\n                \"Your answer:\",\n                key=f\"completion_{i}\",\n                placeholder=\"Type your answer here...\"\n            )\n            \n            if answer:\n                completion['answers'][i] = answer\n            \n            st.markdown(\"---\")\n        \n        # Submit exercises\n        if len(completion['answers']) == len(completion['exercises']):\n            if st.button(\"âœ… Submit Exercises\", type=\"primary\"):\n                # Evaluate answers\n                results = []\n                total_score = 0\n                \n                for i, exercise in enumerate(completion['exercises']):\n                    user_answer = completion['answers'].get(i, \"\")\n                    evaluation = orchestrator.evaluate_answer(\n                        f\"Complete: {exercise['sentence']}\",\n                        exercise['correct_answer'],\n                        user_answer\n                    )\n                    results.append(evaluation)\n                    total_score += evaluation['score']\n                \n                avg_score = total_score / len(completion['exercises'])\n                \n                # Show results\n                st.success(f\"Exercises completed! Average Score: {avg_score:.1f}%\")\n                \n                st.subheader(\"ðŸ“‹ Detailed Feedback\")\n                for i, (exercise, result) in enumerate(zip(completion['exercises'], results)):\n                    status_icon = \"âœ…\" if result['is_correct'] else \"âŒ\"\n                    st.markdown(f\"{status_icon} **Exercise {i+1}:** Score: {result['score']:.1f}%\")\n                    st.markdown(f\"Sentence: {exercise['sentence']}\")\n                    st.markdown(f\"Your answer: **{completion['answers'][i]}**\")\n                    st.markdown(f\"Expected answer: **{exercise['correct_answer']}**\")\n                    st.markdown(f\"Feedback: {result['feedback']}\")\n                    st.markdown(\"---\")\n                \n                # Save to history\n                quiz_result = {\n                    'id': f\"completion_{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n                    'type': 'sentence_completion',\n                    'document_id': completion['document_id'],\n                    'document_title': completion['document_title'],\n                    'score': avg_score,\n                    'total_questions': len(completion['exercises']),\n                    'completed_at': datetime.now().isoformat()\n                }\n                st.session_state.quiz_history.append(quiz_result)\n                log_activity(f\"Completed sentence completion on {completion['document_title']} - Score: {avg_score:.1f}%\")\n                \n                # Clear current exercise\n                st.session_state.current_completion = None\n\nwith tab3:\n    st.subheader(\"Q&A Exercise\")\n    st.markdown(\"Generate questions and evaluate your understanding\")\n    \n    # Document selection\n    doc_options = {doc['title']: doc['id'] for doc in st.session_state.documents}\n    selected_title = st.selectbox(\n        \"Select Document\",\n        options=list(doc_options.keys()),\n        key=\"qa_doc\"\n    )\n    selected_doc = get_document_by_id(doc_options[selected_title])\n    \n    st.markdown(\"**Ask a question about the document:**\")\n    user_question = st.text_area(\n        \"Your Question:\",\n        placeholder=\"What are the main concepts discussed in this document?\",\n        height=100\n    )\n    \n    if user_question and st.button(\"ðŸ“ Generate Answer & Evaluate\", type=\"primary\"):\n        with st.spinner(\"Generating reference answer...\"):\n            # Generate reference answer\n            reference_prompt = f\"\"\"\n            Based on the following document, provide a comprehensive answer to this question: {user_question}\n            \n            Document content:\n            {selected_doc['content'][:3000]}...\n            \n            Provide a detailed, accurate answer based only on the document content.\n            \"\"\"\n            \n            try:\n                response = orchestrator.client.models.generate_content(\n                    model=\"gemini-2.5-flash\",\n                    contents=reference_prompt\n                )\n                reference_answer = response.text\n                \n                st.subheader(\"ðŸ“– Reference Answer\")\n                st.markdown(reference_answer)\n                \n                st.subheader(\"âœï¸ Your Turn\")\n                user_answer = st.text_area(\n                    \"Provide your answer to the question:\",\n                    height=150,\n                    placeholder=\"Write your answer here...\"\n                )\n                \n                if user_answer and st.button(\"ðŸ” Evaluate My Answer\"):\n                    with st.spinner(\"Evaluating your answer...\"):\n                        evaluation = orchestrator.evaluate_answer(\n                            user_question,\n                            reference_answer,\n                            user_answer\n                        )\n                    \n                    # Show evaluation\n                    score_color = \"green\" if evaluation['score'] >= 70 else \"orange\" if evaluation['score'] >= 50 else \"red\"\n                    \n                    st.markdown(f\"### ðŸ“Š Evaluation Result\")\n                    st.markdown(f\"**Score:** :{score_color}[{evaluation['score']:.1f}%]\")\n                    st.markdown(f\"**Status:** {'âœ… Correct' if evaluation['is_correct'] else 'âŒ Needs Improvement'}\")\n                    \n                    st.markdown(\"**Feedback:**\")\n                    st.info(evaluation['feedback'])\n                    \n                    # Save to history\n                    qa_result = {\n                        'id': f\"qa_{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n                        'type': 'qa_exercise',\n                        'document_id': selected_doc['id'],\n                        'document_title': selected_doc['title'],\n                        'question': user_question,\n                        'user_answer': user_answer,\n                        'reference_answer': reference_answer,\n                        'score': evaluation['score'],\n                        'completed_at': datetime.now().isoformat()\n                    }\n                    st.session_state.quiz_history.append(qa_result)\n                    log_activity(f\"Completed Q&A exercise on {selected_doc['title']} - Score: {evaluation['score']:.1f}%\")\n                \n            except Exception as e:\n                st.error(f\"Error generating reference answer: {e}\")\n\nwith tab4:\n    st.subheader(\"ðŸ“ˆ Quiz History\")\n    \n    if not st.session_state.quiz_history:\n        st.info(\"No quiz history yet. Complete some quizzes to see your progress!\")\n    else:\n        # Summary stats\n        total_quizzes = len(st.session_state.quiz_history)\n        avg_score = sum(q.get('score', 0) for q in st.session_state.quiz_history) / total_quizzes\n        \n        col1, col2, col3 = st.columns(3)\n        with col1:\n            st.metric(\"Total Quizzes\", total_quizzes)\n        with col2:\n            st.metric(\"Average Score\", f\"{avg_score:.1f}%\")\n        with col3:\n            recent_score = st.session_state.quiz_history[-1].get('score', 0) if st.session_state.quiz_history else 0\n            st.metric(\"Latest Score\", f\"{recent_score:.1f}%\")\n        \n        st.markdown(\"---\")\n        \n        # Quiz history table\n        for quiz in reversed(st.session_state.quiz_history[-10:]):  # Show last 10\n            quiz_type_icons = {\n                'multiple_choice': 'ðŸŽ¯',\n                'sentence_completion': 'âœï¸',\n                'qa_exercise': 'ðŸ’¬'\n            }\n            \n            icon = quiz_type_icons.get(quiz['type'], 'ðŸ“')\n            \n            with st.expander(f\"{icon} {quiz['type'].replace('_', ' ').title()} - {quiz['document_title'][:50]}... - {quiz['score']:.1f}%\"):\n                col1, col2 = st.columns(2)\n                with col1:\n                    st.markdown(f\"**Document:** {quiz['document_title']}\")\n                    st.markdown(f\"**Type:** {quiz['type'].replace('_', ' ').title()}\")\n                    st.markdown(f\"**Score:** {quiz['score']:.1f}%\")\n                \n                with col2:\n                    st.markdown(f\"**Completed:** {quiz['completed_at'][:16]}\")\n                    if quiz.get('total_questions'):\n                        st.markdown(f\"**Questions:** {quiz.get('correct_answers', 0)}/{quiz['total_questions']}\")\n                    if quiz.get('difficulty'):\n                        st.markdown(f\"**Difficulty:** {quiz['difficulty']}\")\n","size_bytes":17254},"pages/3_ðŸ“_Summaries.py":{"content":"import streamlit as st\nfrom backend.auth import check_authentication, render_logout_button\nfrom backend.utils import initialize_session_state, log_activity, get_document_by_id\nfrom backend.orchestrator import AIOrchestrator\nfrom datetime import datetime\nimport uuid\n\n# Page configuration\nst.set_page_config(\n    page_title=\"Summaries - DocGen\",\n    page_icon=\"ðŸ“\",\n    layout=\"wide\"\n)\n\n# Authentication check\nif not check_authentication():\n    st.error(\"Please log in from the main page first.\")\n    st.stop()\n\n# Initialize session state\ninitialize_session_state()\n\n# Render logout button\nrender_logout_button()\n\n# Initialize AI orchestrator\n@st.cache_resource\ndef get_orchestrator():\n    return AIOrchestrator()\n\ntry:\n    orchestrator = get_orchestrator()\nexcept ValueError as e:\n    st.error(f\"AI Service Error: {e}\")\n    st.stop()\n\nst.title(\"ðŸ“ Document Summaries\")\nst.markdown(\"Generate AI-powered summaries of your documents with markdown formatting.\")\n\n# Check if a document was selected for summary\nselected_doc_id = st.session_state.get('selected_doc_for_summary')\n\nif not st.session_state.documents:\n    st.warning(\"No documents in your library. Please upload documents first.\")\n    if st.button(\"ðŸ“š Go to Document Library\"):\n        st.switch_page(\"pages/1_ðŸ“š_Document_Library.py\")\n    st.stop()\n\n# Tabs for different summary functions\ntab1, tab2 = st.tabs([\"ðŸ“„ Generate Summary\", \"ðŸ“š Summary Library\"])\n\nwith tab1:\n    st.subheader(\"Generate New Summary\")\n    \n    # Document selection\n    doc_options = {doc['title']: doc['id'] for doc in st.session_state.documents}\n    \n    # Pre-select document if coming from library\n    default_index = 0\n    if selected_doc_id and selected_doc_id in doc_options.values():\n        doc_titles = list(doc_options.keys())\n        doc_ids = list(doc_options.values())\n        default_index = doc_ids.index(selected_doc_id)\n    \n    selected_title = st.selectbox(\n        \"Select Document to Summarize\",\n        options=list(doc_options.keys()),\n        index=default_index,\n        help=\"Choose a document from your library to generate a summary\"\n    )\n    \n    selected_doc = get_document_by_id(doc_options[selected_title])\n    \n    if selected_doc:\n        # Document preview\n        with st.expander(\"ðŸ“– Document Preview\"):\n            col1, col2, col3 = st.columns(3)\n            with col1:\n                st.metric(\"Word Count\", f\"{selected_doc.get('word_count', 0):,}\")\n            with col2:\n                st.metric(\"Type\", selected_doc['type'].title())\n            with col3:\n                if selected_doc.get('authors'):\n                    st.write(f\"**Authors:** {', '.join(selected_doc['authors'])}\")\n            \n            # Content preview\n            preview_text = selected_doc['content'][:500]\n            st.markdown(f\"**Content Preview:**\\n\\n{preview_text}...\")\n        \n        # Summary options\n        st.subheader(\"Summary Options\")\n        \n        col1, col2 = st.columns(2)\n        with col1:\n            summary_style = st.selectbox(\n                \"Summary Style\",\n                [\"Comprehensive\", \"Bullet Points\", \"Executive Summary\", \"Study Notes\"],\n                help=\"Choose the style of summary you prefer\"\n            )\n        \n        with col2:\n            include_concepts = st.checkbox(\n                \"Include Key Concepts\",\n                value=True,\n                help=\"Extract and highlight key concepts and terms\"\n            )\n        \n        # Generate summary button\n        if st.button(\"âœ¨ Generate Summary\", type=\"primary\", use_container_width=True):\n            with st.spinner(\"Generating summary... This may take a moment.\"):\n                try:\n                    # Create custom prompt based on options\n                    style_prompts = {\n                        \"Comprehensive\": \"Create a comprehensive, detailed summary\",\n                        \"Bullet Points\": \"Create a summary using bullet points and clear structure\",\n                        \"Executive Summary\": \"Create an executive summary focusing on key insights\",\n                        \"Study Notes\": \"Create study-friendly notes with important points highlighted\"\n                    }\n                    \n                    style_instruction = style_prompts.get(summary_style, \"Create a comprehensive summary\")\n                    \n                    # Generate the summary\n                    summary_text = orchestrator.generate_summary(\n                        selected_doc['content'],\n                        selected_doc['title']\n                    )\n                    \n                    if summary_text and \"Error\" not in summary_text:\n                        # Extract key concepts if requested\n                        key_concepts = []\n                        if include_concepts:\n                            key_concepts = orchestrator.extract_key_concepts(selected_doc['content'])\n                        \n                        # Create summary record\n                        summary_record = {\n                            'id': str(uuid.uuid4()),\n                            'document_id': selected_doc['id'],\n                            'document_title': selected_doc['title'],\n                            'summary': summary_text,\n                            'style': summary_style,\n                            'key_concepts': key_concepts,\n                            'created_at': datetime.now().isoformat(),\n                            'word_count': len(summary_text.split())\n                        }\n                        \n                        # Add to session state\n                        st.session_state.summaries.append(summary_record)\n                        \n                        # Log activity\n                        log_activity(f\"Generated summary for: {selected_doc['title']}\")\n                        \n                        st.success(\"âœ… Summary generated successfully!\")\n                        \n                        # Display the summary\n                        st.markdown(\"---\")\n                        st.subheader(f\"ðŸ“„ Summary: {selected_doc['title']}\")\n                        \n                        # Summary metadata\n                        col1, col2, col3 = st.columns(3)\n                        with col1:\n                            st.metric(\"Summary Length\", f\"{len(summary_text.split())} words\")\n                        with col2:\n                            st.metric(\"Style\", summary_style)\n                        with col3:\n                            st.metric(\"Concepts\", len(key_concepts))\n                        \n                        # Display key concepts if available\n                        if key_concepts:\n                            st.subheader(\"ðŸ”‘ Key Concepts\")\n                            concept_cols = st.columns(min(3, len(key_concepts)))\n                            for i, concept in enumerate(key_concepts[:6]):  # Show first 6 concepts\n                                with concept_cols[i % 3]:\n                                    st.info(concept)\n                        \n                        # Display the summary content\n                        st.subheader(\"ðŸ“ Summary Content\")\n                        st.markdown(summary_text)\n                        \n                        # Download option\n                        st.download_button(\n                            \"ðŸ’¾ Download Summary\",\n                            data=f\"# {selected_doc['title']}\\n\\n## Summary\\n\\n{summary_text}\\n\\n## Key Concepts\\n\\n{', '.join(key_concepts)}\",\n                            file_name=f\"summary_{selected_doc['title'][:30]}.md\",\n                            mime=\"text/markdown\",\n                            help=\"Download summary as markdown file\"\n                        )\n                        \n                        # Clear the selected document\n                        if 'selected_doc_for_summary' in st.session_state:\n                            del st.session_state.selected_doc_for_summary\n                    \n                    else:\n                        st.error(\"Failed to generate summary. Please try again.\")\n                \n                except Exception as e:\n                    st.error(f\"Error generating summary: {e}\")\n\nwith tab2:\n    st.subheader(\"Summary Library\")\n    \n    if not st.session_state.summaries:\n        st.info(\"No summaries generated yet. Create your first summary using the 'Generate Summary' tab!\")\n    else:\n        # Summary statistics\n        total_summaries = len(st.session_state.summaries)\n        total_summary_words = sum(s.get('word_count', 0) for s in st.session_state.summaries)\n        \n        col1, col2, col3 = st.columns(3)\n        with col1:\n            st.metric(\"ðŸ“ Total Summaries\", total_summaries)\n        with col2:\n            st.metric(\"ðŸ“Š Total Words\", f\"{total_summary_words:,}\")\n        with col3:\n            avg_length = total_summary_words // total_summaries if total_summaries > 0 else 0\n            st.metric(\"ðŸ“ Avg Length\", f\"{avg_length} words\")\n        \n        st.markdown(\"---\")\n        \n        # Search summaries\n        search_term = st.text_input(\n            \"ðŸ” Search Summaries\",\n            placeholder=\"Search by document title or content...\",\n            help=\"Search through your summary library\"\n        )\n        \n        # Filter summaries\n        filtered_summaries = st.session_state.summaries\n        if search_term:\n            filtered_summaries = [\n                s for s in st.session_state.summaries\n                if search_term.lower() in s['document_title'].lower() or \n                   search_term.lower() in s['summary'].lower()\n            ]\n        \n        # Display summaries\n        for summary in reversed(filtered_summaries):  # Most recent first\n            with st.expander(f\"ðŸ“„ {summary['document_title']} - {summary['created_at'][:10]}\"):\n                # Summary metadata\n                col1, col2, col3, col4 = st.columns(4)\n                with col1:\n                    st.markdown(f\"**Style:** {summary['style']}\")\n                with col2:\n                    st.markdown(f\"**Length:** {summary.get('word_count', 0)} words\")\n                with col3:\n                    st.markdown(f\"**Created:** {summary['created_at'][:10]}\")\n                with col4:\n                    st.markdown(f\"**Concepts:** {len(summary.get('key_concepts', []))}\")\n                \n                # Key concepts\n                if summary.get('key_concepts'):\n                    st.markdown(\"**ðŸ”‘ Key Concepts:**\")\n                    concepts_text = \" â€¢ \".join(summary['key_concepts'][:8])  # First 8 concepts\n                    st.markdown(f\"*{concepts_text}*\")\n                \n                # Summary content\n                st.markdown(\"**ðŸ“ Summary:**\")\n                st.markdown(summary['summary'])\n                \n                # Action buttons\n                col1, col2, col3 = st.columns(3)\n                with col1:\n                    # Download button\n                    st.download_button(\n                        \"ðŸ’¾ Download\",\n                        data=f\"# {summary['document_title']}\\n\\n## Summary\\n\\n{summary['summary']}\\n\\n## Key Concepts\\n\\n{', '.join(summary.get('key_concepts', []))}\",\n                        file_name=f\"summary_{summary['document_title'][:30]}.md\",\n                        mime=\"text/markdown\",\n                        key=f\"download_{summary['id']}\"\n                    )\n                \n                with col2:\n                    # Create quiz from summary\n                    if st.button(\"ðŸ§  Create Quiz\", key=f\"quiz_{summary['id']}\"):\n                        # Find the original document\n                        orig_doc = get_document_by_id(summary['document_id'])\n                        if orig_doc:\n                            st.session_state.selected_doc_for_quiz = orig_doc['id']\n                            st.switch_page(\"pages/2_ðŸ§ _Quiz_Center.py\")\n                        else:\n                            st.error(\"Original document not found\")\n                \n                with col3:\n                    # Delete summary\n                    if st.button(\"ðŸ—‘ï¸ Delete\", key=f\"delete_{summary['id']}\", type=\"secondary\"):\n                        # Remove from summaries\n                        st.session_state.summaries = [s for s in st.session_state.summaries if s['id'] != summary['id']]\n                        log_activity(f\"Deleted summary for: {summary['document_title']}\")\n                        st.success(\"Summary deleted!\")\n                        st.rerun()\n\n# Sidebar with summary tips\nwith st.sidebar:\n    st.markdown(\"### ðŸ’¡ Summary Tips\")\n    st.markdown(\"\"\"\n    **Best Practices:**\n    - Longer documents create more detailed summaries\n    - Use 'Key Concepts' for study materials\n    - Executive summaries work well for research papers\n    - Bullet points are great for quick reference\n    \n    **Summary Styles:**\n    - **Comprehensive**: Detailed, paragraph format\n    - **Bullet Points**: Structured, easy to scan\n    - **Executive**: High-level insights\n    - **Study Notes**: Learning-focused\n    \"\"\")\n","size_bytes":13159},"pages/4_ðŸ“Š_Dashboard.py":{"content":"import streamlit as st\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom datetime import datetime, timedelta\nimport pandas as pd\nfrom collections import defaultdict\nfrom backend.auth import check_authentication, render_logout_button\nfrom backend.utils import initialize_session_state\n\n# Page configuration\nst.set_page_config(\n    page_title=\"Dashboard - DocGen\",\n    page_icon=\"ðŸ“Š\",\n    layout=\"wide\"\n)\n\n# Authentication check\nif not check_authentication():\n    st.error(\"Please log in from the main page first.\")\n    st.stop()\n\n# Initialize session state\ninitialize_session_state()\n\n# Render logout button\nrender_logout_button()\n\nst.title(\"ðŸ“Š Learning Dashboard\")\nst.markdown(\"Track your learning progress and performance metrics.\")\n\n# Helper functions\ndef get_date_from_iso(iso_string):\n    \"\"\"Convert ISO string to date\"\"\"\n    try:\n        return datetime.fromisoformat(iso_string.replace('Z', '+00:00')).date()\n    except:\n        return datetime.now().date()\n\ndef calculate_performance_metrics():\n    \"\"\"Calculate performance metrics from quiz history\"\"\"\n    if not st.session_state.quiz_history:\n        return {}\n    \n    metrics = {\n        'total_quizzes': len(st.session_state.quiz_history),\n        'average_score': sum(q.get('score', 0) for q in st.session_state.quiz_history) / len(st.session_state.quiz_history),\n        'best_score': max(q.get('score', 0) for q in st.session_state.quiz_history),\n        'recent_score': st.session_state.quiz_history[-1].get('score', 0) if st.session_state.quiz_history else 0\n    }\n    \n    # Quiz type breakdown\n    type_counts = defaultdict(int)\n    type_scores = defaultdict(list)\n    \n    for quiz in st.session_state.quiz_history:\n        quiz_type = quiz.get('type', 'unknown')\n        type_counts[quiz_type] += 1\n        type_scores[quiz_type].append(quiz.get('score', 0))\n    \n    metrics['type_breakdown'] = dict(type_counts)\n    metrics['type_averages'] = {k: sum(v) / len(v) for k, v in type_scores.items()}\n    \n    return metrics\n\ndef generate_activity_calendar():\n    \"\"\"Generate activity calendar data\"\"\"\n    activity_data = defaultdict(int)\n    \n    # Count activities by date\n    for activity in st.session_state.activity_log:\n        try:\n            date = datetime.fromisoformat(activity['timestamp'].replace('Z', '+00:00')).date()\n            activity_data[date] += 1\n        except:\n            continue\n    \n    # Generate last 90 days\n    end_date = datetime.now().date()\n    start_date = end_date - timedelta(days=89)\n    \n    dates = []\n    activities = []\n    \n    current_date = start_date\n    while current_date <= end_date:\n        dates.append(current_date)\n        activities.append(activity_data.get(current_date, 0))\n        current_date += timedelta(days=1)\n    \n    return dates, activities\n\n# Main dashboard content\nif not st.session_state.quiz_history and not st.session_state.documents:\n    st.info(\"Welcome to your dashboard! Start by uploading documents and taking quizzes to see your progress here.\")\n    col1, col2 = st.columns(2)\n    with col1:\n        if st.button(\"ðŸ“š Upload Documents\", use_container_width=True):\n            st.switch_page(\"pages/1_ðŸ“š_Document_Library.py\")\n    with col2:\n        if st.button(\"ðŸ§  Take Quiz\", use_container_width=True):\n            st.switch_page(\"pages/2_ðŸ§ _Quiz_Center.py\")\n    st.stop()\n\n# Key metrics row\nst.subheader(\"ðŸ“ˆ Key Metrics\")\n\ncol1, col2, col3, col4 = st.columns(4)\n\nwith col1:\n    st.metric(\n        label=\"ðŸ“„ Documents\",\n        value=len(st.session_state.documents),\n        help=\"Total documents in your library\"\n    )\n\nwith col2:\n    total_quizzes = len(st.session_state.quiz_history)\n    st.metric(\n        label=\"ðŸŽ¯ Quizzes Taken\",\n        value=total_quizzes,\n        help=\"Total number of quizzes completed\"\n    )\n\nwith col3:\n    st.metric(\n        label=\"ðŸ“ Summaries\",\n        value=len(st.session_state.summaries),\n        help=\"Total summaries generated\"\n    )\n\nwith col4:\n    avg_score = 0\n    if st.session_state.quiz_history:\n        scores = [q.get('score', 0) for q in st.session_state.quiz_history]\n        avg_score = sum(scores) / len(scores)\n    \n    # Calculate delta from previous average\n    delta = None\n    if len(st.session_state.quiz_history) >= 2:\n        recent_scores = scores[-3:] if len(scores) >= 3 else scores[-2:]\n        prev_scores = scores[:-len(recent_scores)]\n        if prev_scores:\n            prev_avg = sum(prev_scores) / len(prev_scores)\n            recent_avg = sum(recent_scores) / len(recent_scores)\n            delta = f\"{recent_avg - prev_avg:.1f}%\"\n    \n    st.metric(\n        label=\"ðŸ“Š Avg Score\",\n        value=f\"{avg_score:.1f}%\",\n        delta=delta,\n        help=\"Average quiz score across all attempts\"\n    )\n\n# Performance analysis\nif st.session_state.quiz_history:\n    metrics = calculate_performance_metrics()\n    \n    st.markdown(\"---\")\n    st.subheader(\"ðŸŽ¯ Performance Analysis\")\n    \n    # Score trend chart\n    col1, col2 = st.columns([2, 1])\n    \n    with col1:\n        st.markdown(\"**ðŸ“ˆ Score Trend Over Time**\")\n        \n        # Prepare data for trend chart\n        quiz_dates = []\n        quiz_scores = []\n        quiz_types = []\n        \n        for i, quiz in enumerate(st.session_state.quiz_history):\n            quiz_dates.append(i + 1)  # Use quiz number as x-axis\n            quiz_scores.append(quiz.get('score', 0))\n            quiz_types.append(quiz.get('type', 'unknown').replace('_', ' ').title())\n        \n        # Create trend chart\n        fig = px.line(\n            x=quiz_dates,\n            y=quiz_scores,\n            title=\"Quiz Score Progression\",\n            labels={'x': 'Quiz Number', 'y': 'Score (%)'},\n            markers=True\n        )\n        \n        # Add target line at 80%\n        fig.add_hline(y=80, line_dash=\"dash\", line_color=\"green\", \n                     annotation_text=\"Target: 80%\")\n        \n        fig.update_layout(\n            showlegend=False,\n            height=300,\n            margin=dict(l=20, r=20, t=40, b=20)\n        )\n        \n        st.plotly_chart(fig, use_container_width=True)\n    \n    with col2:\n        st.markdown(\"**ðŸ† Performance Highlights**\")\n        \n        st.metric(\"Best Score\", f\"{metrics['best_score']:.1f}%\")\n        st.metric(\"Recent Score\", f\"{metrics['recent_score']:.1f}%\")\n        \n        # Progress towards goals\n        if avg_score >= 90:\n            st.success(\"ðŸŒŸ Excellent Performance!\")\n        elif avg_score >= 80:\n            st.success(\"âœ… Great Job!\")\n        elif avg_score >= 70:\n            st.info(\"ðŸ‘ Good Progress!\")\n        else:\n            st.warning(\"ðŸ“š Keep Studying!\")\n    \n    # Quiz type analysis\n    st.markdown(\"**ðŸ“Š Quiz Type Performance**\")\n    \n    if len(metrics['type_breakdown']) > 1:\n        col1, col2 = st.columns(2)\n        \n        with col1:\n            # Quiz type distribution\n            fig_pie = px.pie(\n                values=list(metrics['type_breakdown'].values()),\n                names=[t.replace('_', ' ').title() for t in metrics['type_breakdown'].keys()],\n                title=\"Quiz Type Distribution\"\n            )\n            fig_pie.update_layout(height=300, margin=dict(l=20, r=20, t=40, b=20))\n            st.plotly_chart(fig_pie, use_container_width=True)\n        \n        with col2:\n            # Average scores by type\n            fig_bar = px.bar(\n                x=[t.replace('_', ' ').title() for t in metrics['type_averages'].keys()],\n                y=list(metrics['type_averages'].values()),\n                title=\"Average Score by Quiz Type\",\n                labels={'x': 'Quiz Type', 'y': 'Average Score (%)'}\n            )\n            fig_bar.update_layout(height=300, margin=dict(l=20, r=20, t=40, b=20))\n            st.plotly_chart(fig_bar, use_container_width=True)\n    else:\n        # Single type display\n        quiz_type = list(metrics['type_breakdown'].keys())[0]\n        avg_score_type = metrics['type_averages'][quiz_type]\n        \n        st.info(f\"**{quiz_type.replace('_', ' ').title()}**: {metrics['type_breakdown'][quiz_type]} quizzes, {avg_score_type:.1f}% average\")\n\n# Activity calendar\nst.markdown(\"---\")\nst.subheader(\"ðŸ“… Activity Calendar\")\n\nif st.session_state.activity_log:\n    dates, activities = generate_activity_calendar()\n    \n    # Create calendar heatmap\n    df_calendar = pd.DataFrame({\n        'Date': dates,\n        'Activities': activities,\n        'Day': [d.strftime('%A') for d in dates],\n        'Week': [(d - dates[0]).days // 7 for d in dates]\n    })\n    \n    # Pivot for heatmap\n    calendar_pivot = df_calendar.pivot_table(\n        index='Day',\n        columns='Week',\n        values='Activities',\n        fill_value=0\n    )\n    \n    # Reorder days\n    day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n    calendar_pivot = calendar_pivot.reindex(day_order)\n    \n    fig_heatmap = px.imshow(\n        calendar_pivot,\n        labels=dict(x=\"Week\", y=\"Day\", color=\"Activities\"),\n        title=\"Activity Heatmap (Last 90 Days)\",\n        color_continuous_scale=\"Greens\"\n    )\n    \n    fig_heatmap.update_layout(\n        height=300,\n        xaxis_title=\"Week\",\n        yaxis_title=\"\",\n        margin=dict(l=20, r=20, t=40, b=20)\n    )\n    \n    st.plotly_chart(fig_heatmap, use_container_width=True)\n    \n    # Activity summary\n    total_active_days = sum(1 for a in activities if a > 0)\n    current_streak = 0\n    \n    # Calculate current streak\n    for activity in reversed(activities):\n        if activity > 0:\n            current_streak += 1\n        else:\n            break\n    \n    col1, col2, col3 = st.columns(3)\n    with col1:\n        st.metric(\"ðŸ”¥ Current Streak\", f\"{current_streak} days\")\n    with col2:\n        st.metric(\"ðŸ“Š Active Days\", f\"{total_active_days}/90\")\n    with col3:\n        activity_rate = (total_active_days / 90) * 100\n        st.metric(\"ðŸ“ˆ Activity Rate\", f\"{activity_rate:.1f}%\")\n\nelse:\n    st.info(\"No activity data available yet. Start using the app to see your activity calendar!\")\n\n# Recent activity feed\nst.markdown(\"---\")\nst.subheader(\"ðŸ•’ Recent Activity\")\n\nif st.session_state.activity_log:\n    # Show last 10 activities\n    recent_activities = st.session_state.activity_log[-10:]\n    \n    for activity in reversed(recent_activities):\n        timestamp = activity['timestamp']\n        action = activity['action']\n        \n        # Format timestamp\n        try:\n            dt = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))\n            time_str = dt.strftime('%m/%d %H:%M')\n        except:\n            time_str = timestamp\n        \n        st.info(f\"**{time_str}** - {action}\")\n\nelse:\n    st.info(\"No recent activity. Start by uploading documents or taking quizzes!\")\n\n# Learning insights\nst.markdown(\"---\")\nst.subheader(\"ðŸ’¡ Learning Insights\")\n\ninsights = []\n\nif st.session_state.quiz_history:\n    # Performance insights\n    if avg_score >= 85:\n        insights.append(\"ðŸŒŸ Excellent work! Your average score shows strong understanding.\")\n    elif avg_score >= 75:\n        insights.append(\"ðŸ‘ Good performance! Consider challenging yourself with harder material.\")\n    else:\n        insights.append(\"ðŸ“š Focus on reviewing material before taking quizzes to improve scores.\")\n    \n    # Activity insights\n    if len(st.session_state.quiz_history) >= 5:\n        recent_scores = [q.get('score', 0) for q in st.session_state.quiz_history[-5:]]\n        if all(score >= 80 for score in recent_scores):\n            insights.append(\"ðŸ”¥ Great consistency! Your recent scores are all above 80%.\")\n    \n    # Content insights\n    if len(st.session_state.documents) > len(st.session_state.quiz_history):\n        insights.append(\"ðŸ“– You have more documents than completed quizzes. Try creating quizzes from more of your materials.\")\n\n# Document insights\nif st.session_state.documents:\n    doc_types = [doc.get('source', 'unknown') for doc in st.session_state.documents]\n    if 'arxiv' in doc_types and 'upload' in doc_types:\n        insights.append(\"ðŸ”¬ Great mix of academic papers and personal documents!\")\n\n# Summary insights\nif len(st.session_state.summaries) > 0:\n    summary_ratio = len(st.session_state.summaries) / len(st.session_state.documents) if st.session_state.documents else 0\n    if summary_ratio >= 0.5:\n        insights.append(\"ðŸ“ Excellent! You're creating summaries for most of your documents.\")\n\nif insights:\n    for insight in insights:\n        st.success(insight)\nelse:\n    st.info(\"Keep using DocGen to unlock personalized learning insights!\")\n\n# Goals section\nwith st.sidebar:\n    st.subheader(\"ðŸŽ¯ Learning Goals\")\n    \n    # Weekly goal\n    weekly_target = st.number_input(\"Weekly Quiz Target\", min_value=1, max_value=20, value=3)\n    \n    # Calculate this week's progress\n    today = datetime.now().date()\n    week_start = today - timedelta(days=today.weekday())\n    \n    this_week_quizzes = sum(\n        1 for quiz in st.session_state.quiz_history\n        if get_date_from_iso(quiz.get('completed_at', '')) >= week_start\n    )\n    \n    st.progress(min(this_week_quizzes / weekly_target, 1.0))\n    st.caption(f\"This week: {this_week_quizzes}/{weekly_target} quizzes\")\n    \n    # Score goal\n    score_target = st.slider(\"Target Average Score\", 60, 100, 80)\n    \n    if st.session_state.quiz_history:\n        score_progress = min(avg_score / score_target, 1.0)\n        st.progress(score_progress)\n        st.caption(f\"Current: {avg_score:.1f}% / {score_target}%\")\n","size_bytes":13442}},"version":1}